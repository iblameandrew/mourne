"""
Final Director for Mourne.
Takes all generated media assets with stitching cards and produces
a MoviePy script for user approval and execution.
"""
from typing import List, Optional
from .models import VideoProject, MediaAsset, MediaType, TransitionType, KenBurnsDirection
from .llm_backend import get_code_llm, OpenRouterLLM


DIRECTOR_SYSTEM_PROMPT = """You are an expert video editor and Python programmer specialized in MoviePy.
You generate complete, runnable Python scripts that assemble cinematic videos from provided assets.
Your code is clean, well-commented, and handles edge cases gracefully."""


DIRECTOR_PROMPT_TEMPLATE = """
Generate a complete, runnable Python script using MoviePy to assemble a cinematic video.

**Project: {project_name}**
**Audio Track:** {song_path}
**Total Duration:** {total_duration} seconds

**Assets and Stitching Cards:**
{assets_description}

**Requirements:**
1. Use `moviepy.editor` for all video operations
2. Load each asset (image or video) at its specified time_start
3. For IMAGES:
   - Apply Ken Burns effect (slow zoom/pan) as specified in ken_burns_direction
   - Duration should match (time_end - time_start)
4. For VIDEOS:
   - Trim if needed to match the specified duration
   - Speed up/slow down if the generated duration doesn't match required duration
5. Apply transitions between clips as specified (crossfade duration: {transition_duration}s)
6. Color grading hints are provided - apply subtle adjustments if possible
7. Load and sync the audio track
8. Handle resolution mismatches (resize all to 1920x1080)

**Script Structure:**
```python
#!/usr/bin/env python3
\"\"\"
Auto-generated by Mourne Director
Project: {project_name}
\"\"\"
from moviepy.editor import *
import os

# Configuration
OUTPUT_PATH = "final_output.mp4"
AUDIO_PATH = "{song_path}"
TARGET_RESOLUTION = (1920, 1080)
FPS = 30

def create_ken_burns(image_path, duration, direction, resolution):
    \"\"\"Apply Ken Burns effect to an image\"\"\"
    # Implementation here...

def apply_transition(clip1, clip2, transition_type, duration):
    \"\"\"Apply transition between clips\"\"\"
    # Implementation here...

def main():
    clips = []
    
    # Load and process each asset...
    
    # Concatenate with transitions...
    
    # Add audio...
    
    # Export...

if __name__ == "__main__":
    main()
```

**Important:**
- The script must be complete and runnable with `python script.py`
- Include all necessary imports
- Define helper functions for Ken Burns and transitions
- Add error handling for missing files
- Print progress during rendering

Return ONLY the Python code. No markdown, no explanation.
"""


class Director:
    """
    The Final Director that assembles all media assets into a video processing script.
    The generated script can be reviewed by the user before execution.
    """
    
    def __init__(self, llm: Optional[OpenRouterLLM] = None):
        self.llm = llm or get_code_llm()
    
    async def generate_processing_script(
        self,
        project: VideoProject,
        transition_duration: float = 0.5
    ) -> str:
        """
        Generate a MoviePy script to assemble the final video.
        
        Args:
            project: The video project with all assets
            transition_duration: Duration of transitions in seconds
        
        Returns:
            Complete Python script as a string
        """
        if not project.assets:
            raise ValueError("Project has no generated assets")
        
        # Build detailed asset description
        assets_description = self._format_assets_description(project.assets)
        
        # Calculate total duration from assets
        total_duration = max(a.stitching_card.time_end for a in project.assets)
        
        prompt = DIRECTOR_PROMPT_TEMPLATE.format(
            project_name=project.name,
            song_path=project.song_path,
            total_duration=total_duration,
            assets_description=assets_description,
            transition_duration=transition_duration
        )
        
        script = await self.llm.generate(
            prompt=prompt,
            system=DIRECTOR_SYSTEM_PROMPT,
            temperature=0.3,  # Low temp for code generation
            max_tokens=8192
        )
        
        # Clean up response
        script = self._clean_script(script)
        
        # Store in project
        project.processing_script = script
        
        return script
    
    def _format_assets_description(self, assets: List[MediaAsset]) -> str:
        """Format assets into a readable description for the prompt"""
        lines = []
        
        for asset in sorted(assets, key=lambda a: a.stitching_card.scene_number):
            card = asset.stitching_card
            
            lines.append(f"""
Scene {card.scene_number}:
  - Type: {asset.media_type.value}
  - Path: {asset.asset_path}
  - Time: {card.time_start:.2f}s to {card.time_end:.2f}s (duration: {card.duration:.2f}s)
  - Transition In: {card.transition_in.value}
  - Transition Out: {card.transition_out.value}
  - Mood: {card.mood_description}
  - Color Grade Hint: {card.color_grade_hint or 'neutral'}
  - Ken Burns: {card.ken_burns_direction.value if card.ken_burns_direction else 'N/A'}
  - Audio Context: {card.audio_cue[:100]}...
""")
        
        return "\n".join(lines)
    
    def _clean_script(self, script: str) -> str:
        """Clean up the generated script"""
        # Remove markdown code blocks if present
        script = script.strip()
        
        if script.startswith("```python"):
            script = script[9:]
        elif script.startswith("```"):
            script = script[3:]
        
        if script.endswith("```"):
            script = script[:-3]
        
        return script.strip()
    
    def generate_static_script(
        self,
        project: VideoProject,
        transition_duration: float = 0.5
    ) -> str:
        """
        Generate a deterministic MoviePy script without LLM.
        Use this for consistent, predictable output.
        
        Args:
            project: The video project with all assets
            transition_duration: Duration of transitions in seconds
        
        Returns:
            Complete Python script as a string
        """
        assets = sorted(project.assets, key=lambda a: a.stitching_card.scene_number)
        
        # Build asset loading code
        asset_loads = []
        for i, asset in enumerate(assets):
            card = asset.stitching_card
            
            if asset.media_type == MediaType.IMAGE:
                asset_loads.append(f'''
    # Scene {card.scene_number}: {card.mood_description}
    clip_{i} = create_ken_burns(
        "{asset.asset_path}",
        duration={card.duration:.2f},
        direction="{card.ken_burns_direction.value if card.ken_burns_direction else 'zoom_in'}",
        resolution=TARGET_RESOLUTION
    )''')
            else:
                asset_loads.append(f'''
    # Scene {card.scene_number}: {card.mood_description}
    clip_{i} = VideoFileClip("{asset.asset_path}")
    clip_{i} = clip_{i}.resize(TARGET_RESOLUTION)
    # Adjust duration if needed
    target_duration = {card.duration:.2f}
    if clip_{i}.duration != target_duration:
        clip_{i} = clip_{i}.fx(vfx.speedx, clip_{i}.duration / target_duration)''')
        
        # Build concatenation code
        clip_names = [f"clip_{i}" for i in range(len(assets))]
        
        script = f'''#!/usr/bin/env python3
"""
Auto-generated by Mourne Director
Project: {project.name}
Generated Assets: {len(assets)}
"""
from moviepy.editor import *
import moviepy.video.fx.all as vfx
import numpy as np
import os

# Configuration
OUTPUT_PATH = "final_{project.id}.mp4"
AUDIO_PATH = r"{project.song_path}"
TARGET_RESOLUTION = (1920, 1080)
FPS = 30
TRANSITION_DURATION = {transition_duration}


def create_ken_burns(image_path, duration, direction, resolution):
    """
    Apply Ken Burns effect (slow zoom/pan) to a static image.
    """
    img = ImageClip(image_path).resize(height=resolution[1] * 1.2)
    
    # Center the image
    img = img.set_position('center')
    
    w, h = img.size
    target_w, target_h = resolution
    
    if direction == "zoom_in":
        def zoom(t):
            scale = 1 + (t / duration) * 0.2
            return scale
        img = img.resize(lambda t: zoom(t))
    elif direction == "zoom_out":
        def zoom(t):
            scale = 1.2 - (t / duration) * 0.2
            return scale
        img = img.resize(lambda t: zoom(t))
    elif direction == "pan_right":
        def position(t):
            x = -100 + (t / duration) * 200
            return (x, 'center')
        img = img.set_position(position)
    elif direction == "pan_left":
        def position(t):
            x = 100 - (t / duration) * 200
            return (x, 'center')
        img = img.set_position(position)
    elif direction == "pan_up":
        def position(t):
            y = 50 - (t / duration) * 100
            return ('center', y)
        img = img.set_position(position)
    elif direction == "pan_down":
        def position(t):
            y = -50 + (t / duration) * 100
            return ('center', y)
        img = img.set_position(position)
    
    img = img.set_duration(duration)
    
    # Composite on black background at target resolution
    bg = ColorClip(resolution, color=(0, 0, 0)).set_duration(duration)
    final = CompositeVideoClip([bg, img.set_position('center')])
    
    return final


def apply_crossfade(clips, transition_duration):
    """
    Apply crossfade transitions between clips.
    """
    if len(clips) == 0:
        return None
    if len(clips) == 1:
        return clips[0]
    
    # Use concatenate_videoclips with crossfade
    result = clips[0]
    for clip in clips[1:]:
        result = concatenate_videoclips(
            [result, clip],
            method="compose",
            padding=-transition_duration
        ).crossfadein(transition_duration)
    
    return result


def main():
    print("Starting Mourne Video Assembly...")
    print(f"Project: {project.name}")
    print(f"Output: {{OUTPUT_PATH}}")
    
    clips = []
    
{chr(10).join(asset_loads)}
    
    clips = [{", ".join(clip_names)}]
    
    print(f"Loaded {{len(clips)}} clips")
    
    # Apply transitions
    print("Applying transitions...")
    final_video = apply_crossfade(clips, TRANSITION_DURATION)
    
    # Add audio
    print("Adding audio track...")
    if os.path.exists(AUDIO_PATH):
        audio = AudioFileClip(AUDIO_PATH)
        # Trim audio to video length
        if audio.duration > final_video.duration:
            audio = audio.subclip(0, final_video.duration)
        final_video = final_video.set_audio(audio)
    else:
        print(f"Warning: Audio file not found at {{AUDIO_PATH}}")
    
    # Export
    print("Rendering final video...")
    final_video.write_videofile(
        OUTPUT_PATH,
        fps=FPS,
        codec='libx264',
        audio_codec='aac',
        threads=4,
        preset='medium'
    )
    
    print(f"\\nVideo saved to: {{OUTPUT_PATH}}")
    
    # Cleanup
    final_video.close()


if __name__ == "__main__":
    main()
'''
        
        return script
    
    async def save_script(
        self,
        project: VideoProject,
        output_path: str
    ) -> str:
        """
        Generate and save the processing script to a file.
        
        Args:
            project: The video project
            output_path: Where to save the script
        
        Returns:
            Path to the saved script
        """
        if not project.processing_script:
            await self.generate_processing_script(project)
        
        with open(output_path, 'w') as f:
            f.write(project.processing_script)
        
        return output_path
